{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fJmhIvtZku7y",
        "outputId": "3daf0ae0-caf6-48f2-98a0-aa9ff6f858a8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting unsloth@ git+https://github.com/unslothai/unsloth.git@fc178b5204515ab96dcbced61ea97dc9b9231ab1 (from unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git@fc178b5204515ab96dcbced61ea97dc9b9231ab1)\n",
            "  Cloning https://github.com/unslothai/unsloth.git (to revision fc178b5204515ab96dcbced61ea97dc9b9231ab1) to /tmp/pip-install-pofn3qd7/unsloth_0c4b94895a564610a3bbade98bc4ea0d\n",
            "  Running command git clone --filter=blob:none --quiet https://github.com/unslothai/unsloth.git /tmp/pip-install-pofn3qd7/unsloth_0c4b94895a564610a3bbade98bc4ea0d\n",
            "  Running command git rev-parse -q --verify 'sha^fc178b5204515ab96dcbced61ea97dc9b9231ab1'\n",
            "  Running command git fetch -q https://github.com/unslothai/unsloth.git fc178b5204515ab96dcbced61ea97dc9b9231ab1\n",
            "  Running command git checkout -q fc178b5204515ab96dcbced61ea97dc9b9231ab1\n",
            "  Resolved https://github.com/unslothai/unsloth.git to commit fc178b5204515ab96dcbced61ea97dc9b9231ab1\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting unsloth_zoo>=2025.10.11 (from unsloth@ git+https://github.com/unslothai/unsloth.git@fc178b5204515ab96dcbced61ea97dc9b9231ab1->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git@fc178b5204515ab96dcbced61ea97dc9b9231ab1)\n",
            "  Downloading unsloth_zoo-2025.10.12-py3-none-any.whl.metadata (32 kB)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.12/dist-packages (from unsloth@ git+https://github.com/unslothai/unsloth.git@fc178b5204515ab96dcbced61ea97dc9b9231ab1->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git@fc178b5204515ab96dcbced61ea97dc9b9231ab1) (25.0)\n",
            "Collecting tyro (from unsloth@ git+https://github.com/unslothai/unsloth.git@fc178b5204515ab96dcbced61ea97dc9b9231ab1->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git@fc178b5204515ab96dcbced61ea97dc9b9231ab1)\n",
            "  Downloading tyro-0.9.35-py3-none-any.whl.metadata (12 kB)\n",
            "Collecting transformers!=4.52.0,!=4.52.1,!=4.52.2,!=4.52.3,!=4.53.0,!=4.54.0,!=4.55.0,!=4.55.1,<=4.56.2,>=4.51.3 (from unsloth@ git+https://github.com/unslothai/unsloth.git@fc178b5204515ab96dcbced61ea97dc9b9231ab1->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git@fc178b5204515ab96dcbced61ea97dc9b9231ab1)\n",
            "  Downloading transformers-4.56.2-py3-none-any.whl.metadata (40 kB)\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m40.1/40.1 kB\u001b[0m \u001b[31m3.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting datasets!=4.0.*,!=4.1.0,>=3.4.1 (from unsloth@ git+https://github.com/unslothai/unsloth.git@fc178b5204515ab96dcbced61ea97dc9b9231ab1->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git@fc178b5204515ab96dcbced61ea97dc9b9231ab1)\n",
            "  Downloading datasets-4.3.0-py3-none-any.whl.metadata (18 kB)\n",
            "Requirement already satisfied: sentencepiece>=0.2.0 in /usr/local/lib/python3.12/dist-packages (from unsloth@ git+https://github.com/unslothai/unsloth.git@fc178b5204515ab96dcbced61ea97dc9b9231ab1->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git@fc178b5204515ab96dcbced61ea97dc9b9231ab1) (0.2.1)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.12/dist-packages (from unsloth@ git+https://github.com/unslothai/unsloth.git@fc178b5204515ab96dcbced61ea97dc9b9231ab1->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git@fc178b5204515ab96dcbced61ea97dc9b9231ab1) (4.67.1)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.12/dist-packages (from unsloth@ git+https://github.com/unslothai/unsloth.git@fc178b5204515ab96dcbced61ea97dc9b9231ab1->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git@fc178b5204515ab96dcbced61ea97dc9b9231ab1) (5.9.5)\n",
            "Requirement already satisfied: wheel>=0.42.0 in /usr/local/lib/python3.12/dist-packages (from unsloth@ git+https://github.com/unslothai/unsloth.git@fc178b5204515ab96dcbced61ea97dc9b9231ab1->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git@fc178b5204515ab96dcbced61ea97dc9b9231ab1) (0.45.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (from unsloth@ git+https://github.com/unslothai/unsloth.git@fc178b5204515ab96dcbced61ea97dc9b9231ab1->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git@fc178b5204515ab96dcbced61ea97dc9b9231ab1) (2.0.2)\n",
            "Requirement already satisfied: protobuf in /usr/local/lib/python3.12/dist-packages (from unsloth@ git+https://github.com/unslothai/unsloth.git@fc178b5204515ab96dcbced61ea97dc9b9231ab1->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git@fc178b5204515ab96dcbced61ea97dc9b9231ab1) (5.29.5)\n",
            "Requirement already satisfied: huggingface_hub>=0.34.0 in /usr/local/lib/python3.12/dist-packages (from unsloth@ git+https://github.com/unslothai/unsloth.git@fc178b5204515ab96dcbced61ea97dc9b9231ab1->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git@fc178b5204515ab96dcbced61ea97dc9b9231ab1) (0.36.0)\n",
            "Requirement already satisfied: hf_transfer in /usr/local/lib/python3.12/dist-packages (from unsloth@ git+https://github.com/unslothai/unsloth.git@fc178b5204515ab96dcbced61ea97dc9b9231ab1->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git@fc178b5204515ab96dcbced61ea97dc9b9231ab1) (0.1.9)\n",
            "Collecting bitsandbytes!=0.46.0,!=0.48.0,>=0.45.5 (from unsloth@ git+https://github.com/unslothai/unsloth.git@fc178b5204515ab96dcbced61ea97dc9b9231ab1->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git@fc178b5204515ab96dcbced61ea97dc9b9231ab1)\n",
            "  Downloading bitsandbytes-0.48.2-py3-none-manylinux_2_24_x86_64.whl.metadata (10 kB)\n",
            "Requirement already satisfied: torch<3,>=2.3 in /usr/local/lib/python3.12/dist-packages (from bitsandbytes!=0.46.0,!=0.48.0,>=0.45.5->unsloth@ git+https://github.com/unslothai/unsloth.git@fc178b5204515ab96dcbced61ea97dc9b9231ab1->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git@fc178b5204515ab96dcbced61ea97dc9b9231ab1) (2.8.0+cu126)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from datasets!=4.0.*,!=4.1.0,>=3.4.1->unsloth@ git+https://github.com/unslothai/unsloth.git@fc178b5204515ab96dcbced61ea97dc9b9231ab1->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git@fc178b5204515ab96dcbced61ea97dc9b9231ab1) (3.20.0)\n",
            "Collecting pyarrow>=21.0.0 (from datasets!=4.0.*,!=4.1.0,>=3.4.1->unsloth@ git+https://github.com/unslothai/unsloth.git@fc178b5204515ab96dcbced61ea97dc9b9231ab1->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git@fc178b5204515ab96dcbced61ea97dc9b9231ab1)\n",
            "  Downloading pyarrow-22.0.0-cp312-cp312-manylinux_2_28_x86_64.whl.metadata (3.2 kB)\n",
            "Requirement already satisfied: dill<0.4.1,>=0.3.0 in /usr/local/lib/python3.12/dist-packages (from datasets!=4.0.*,!=4.1.0,>=3.4.1->unsloth@ git+https://github.com/unslothai/unsloth.git@fc178b5204515ab96dcbced61ea97dc9b9231ab1->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git@fc178b5204515ab96dcbced61ea97dc9b9231ab1) (0.3.8)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.12/dist-packages (from datasets!=4.0.*,!=4.1.0,>=3.4.1->unsloth@ git+https://github.com/unslothai/unsloth.git@fc178b5204515ab96dcbced61ea97dc9b9231ab1->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git@fc178b5204515ab96dcbced61ea97dc9b9231ab1) (2.2.2)\n",
            "Requirement already satisfied: requests>=2.32.2 in /usr/local/lib/python3.12/dist-packages (from datasets!=4.0.*,!=4.1.0,>=3.4.1->unsloth@ git+https://github.com/unslothai/unsloth.git@fc178b5204515ab96dcbced61ea97dc9b9231ab1->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git@fc178b5204515ab96dcbced61ea97dc9b9231ab1) (2.32.4)\n",
            "Requirement already satisfied: httpx<1.0.0 in /usr/local/lib/python3.12/dist-packages (from datasets!=4.0.*,!=4.1.0,>=3.4.1->unsloth@ git+https://github.com/unslothai/unsloth.git@fc178b5204515ab96dcbced61ea97dc9b9231ab1->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git@fc178b5204515ab96dcbced61ea97dc9b9231ab1) (0.28.1)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.12/dist-packages (from datasets!=4.0.*,!=4.1.0,>=3.4.1->unsloth@ git+https://github.com/unslothai/unsloth.git@fc178b5204515ab96dcbced61ea97dc9b9231ab1->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git@fc178b5204515ab96dcbced61ea97dc9b9231ab1) (3.6.0)\n",
            "Requirement already satisfied: multiprocess<0.70.17 in /usr/local/lib/python3.12/dist-packages (from datasets!=4.0.*,!=4.1.0,>=3.4.1->unsloth@ git+https://github.com/unslothai/unsloth.git@fc178b5204515ab96dcbced61ea97dc9b9231ab1->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git@fc178b5204515ab96dcbced61ea97dc9b9231ab1) (0.70.16)\n",
            "Requirement already satisfied: fsspec<=2025.9.0,>=2023.1.0 in /usr/local/lib/python3.12/dist-packages (from fsspec[http]<=2025.9.0,>=2023.1.0->datasets!=4.0.*,!=4.1.0,>=3.4.1->unsloth@ git+https://github.com/unslothai/unsloth.git@fc178b5204515ab96dcbced61ea97dc9b9231ab1->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git@fc178b5204515ab96dcbced61ea97dc9b9231ab1) (2025.3.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.12/dist-packages (from datasets!=4.0.*,!=4.1.0,>=3.4.1->unsloth@ git+https://github.com/unslothai/unsloth.git@fc178b5204515ab96dcbced61ea97dc9b9231ab1->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git@fc178b5204515ab96dcbced61ea97dc9b9231ab1) (6.0.3)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.12/dist-packages (from huggingface_hub>=0.34.0->unsloth@ git+https://github.com/unslothai/unsloth.git@fc178b5204515ab96dcbced61ea97dc9b9231ab1->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git@fc178b5204515ab96dcbced61ea97dc9b9231ab1) (4.15.0)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.12/dist-packages (from huggingface_hub>=0.34.0->unsloth@ git+https://github.com/unslothai/unsloth.git@fc178b5204515ab96dcbced61ea97dc9b9231ab1->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git@fc178b5204515ab96dcbced61ea97dc9b9231ab1) (1.2.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.12/dist-packages (from transformers!=4.52.0,!=4.52.1,!=4.52.2,!=4.52.3,!=4.53.0,!=4.54.0,!=4.55.0,!=4.55.1,<=4.56.2,>=4.51.3->unsloth@ git+https://github.com/unslothai/unsloth.git@fc178b5204515ab96dcbced61ea97dc9b9231ab1->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git@fc178b5204515ab96dcbced61ea97dc9b9231ab1) (2024.11.6)\n",
            "Requirement already satisfied: tokenizers<=0.23.0,>=0.22.0 in /usr/local/lib/python3.12/dist-packages (from transformers!=4.52.0,!=4.52.1,!=4.52.2,!=4.52.3,!=4.53.0,!=4.54.0,!=4.55.0,!=4.55.1,<=4.56.2,>=4.51.3->unsloth@ git+https://github.com/unslothai/unsloth.git@fc178b5204515ab96dcbced61ea97dc9b9231ab1->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git@fc178b5204515ab96dcbced61ea97dc9b9231ab1) (0.22.1)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.12/dist-packages (from transformers!=4.52.0,!=4.52.1,!=4.52.2,!=4.52.3,!=4.53.0,!=4.54.0,!=4.55.0,!=4.55.1,<=4.56.2,>=4.51.3->unsloth@ git+https://github.com/unslothai/unsloth.git@fc178b5204515ab96dcbced61ea97dc9b9231ab1->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git@fc178b5204515ab96dcbced61ea97dc9b9231ab1) (0.6.2)\n",
            "Collecting torchao>=0.13.0 (from unsloth_zoo>=2025.10.11->unsloth@ git+https://github.com/unslothai/unsloth.git@fc178b5204515ab96dcbced61ea97dc9b9231ab1->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git@fc178b5204515ab96dcbced61ea97dc9b9231ab1)\n",
            "  Downloading torchao-0.14.1-cp310-abi3-manylinux_2_24_x86_64.manylinux_2_28_x86_64.whl.metadata (19 kB)\n",
            "Requirement already satisfied: triton>=3.0.0 in /usr/local/lib/python3.12/dist-packages (from unsloth_zoo>=2025.10.11->unsloth@ git+https://github.com/unslothai/unsloth.git@fc178b5204515ab96dcbced61ea97dc9b9231ab1->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git@fc178b5204515ab96dcbced61ea97dc9b9231ab1) (3.4.0)\n",
            "Requirement already satisfied: accelerate>=0.34.1 in /usr/local/lib/python3.12/dist-packages (from unsloth_zoo>=2025.10.11->unsloth@ git+https://github.com/unslothai/unsloth.git@fc178b5204515ab96dcbced61ea97dc9b9231ab1->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git@fc178b5204515ab96dcbced61ea97dc9b9231ab1) (1.11.0)\n",
            "Collecting trl!=0.19.0,<=0.23.0,>=0.18.2 (from unsloth_zoo>=2025.10.11->unsloth@ git+https://github.com/unslothai/unsloth.git@fc178b5204515ab96dcbced61ea97dc9b9231ab1->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git@fc178b5204515ab96dcbced61ea97dc9b9231ab1)\n",
            "  Downloading trl-0.23.0-py3-none-any.whl.metadata (11 kB)\n",
            "Requirement already satisfied: peft!=0.11.0,>=0.7.1 in /usr/local/lib/python3.12/dist-packages (from unsloth_zoo>=2025.10.11->unsloth@ git+https://github.com/unslothai/unsloth.git@fc178b5204515ab96dcbced61ea97dc9b9231ab1->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git@fc178b5204515ab96dcbced61ea97dc9b9231ab1) (0.17.1)\n",
            "Collecting cut_cross_entropy (from unsloth_zoo>=2025.10.11->unsloth@ git+https://github.com/unslothai/unsloth.git@fc178b5204515ab96dcbced61ea97dc9b9231ab1->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git@fc178b5204515ab96dcbced61ea97dc9b9231ab1)\n",
            "  Downloading cut_cross_entropy-25.1.1-py3-none-any.whl.metadata (9.3 kB)\n",
            "Requirement already satisfied: pillow in /usr/local/lib/python3.12/dist-packages (from unsloth_zoo>=2025.10.11->unsloth@ git+https://github.com/unslothai/unsloth.git@fc178b5204515ab96dcbced61ea97dc9b9231ab1->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git@fc178b5204515ab96dcbced61ea97dc9b9231ab1) (11.3.0)\n",
            "Collecting msgspec (from unsloth_zoo>=2025.10.11->unsloth@ git+https://github.com/unslothai/unsloth.git@fc178b5204515ab96dcbced61ea97dc9b9231ab1->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git@fc178b5204515ab96dcbced61ea97dc9b9231ab1)\n",
            "  Downloading msgspec-0.19.0-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.9 kB)\n",
            "Requirement already satisfied: docstring-parser>=0.15 in /usr/local/lib/python3.12/dist-packages (from tyro->unsloth@ git+https://github.com/unslothai/unsloth.git@fc178b5204515ab96dcbced61ea97dc9b9231ab1->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git@fc178b5204515ab96dcbced61ea97dc9b9231ab1) (0.17.0)\n",
            "Requirement already satisfied: rich>=11.1.0 in /usr/local/lib/python3.12/dist-packages (from tyro->unsloth@ git+https://github.com/unslothai/unsloth.git@fc178b5204515ab96dcbced61ea97dc9b9231ab1->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git@fc178b5204515ab96dcbced61ea97dc9b9231ab1) (13.9.4)\n",
            "Collecting shtab>=1.5.6 (from tyro->unsloth@ git+https://github.com/unslothai/unsloth.git@fc178b5204515ab96dcbced61ea97dc9b9231ab1->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git@fc178b5204515ab96dcbced61ea97dc9b9231ab1)\n",
            "  Downloading shtab-1.7.2-py3-none-any.whl.metadata (7.4 kB)\n",
            "Requirement already satisfied: typeguard>=4.0.0 in /usr/local/lib/python3.12/dist-packages (from tyro->unsloth@ git+https://github.com/unslothai/unsloth.git@fc178b5204515ab96dcbced61ea97dc9b9231ab1->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git@fc178b5204515ab96dcbced61ea97dc9b9231ab1) (4.4.4)\n",
            "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /usr/local/lib/python3.12/dist-packages (from fsspec[http]<=2025.9.0,>=2023.1.0->datasets!=4.0.*,!=4.1.0,>=3.4.1->unsloth@ git+https://github.com/unslothai/unsloth.git@fc178b5204515ab96dcbced61ea97dc9b9231ab1->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git@fc178b5204515ab96dcbced61ea97dc9b9231ab1) (3.13.1)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.12/dist-packages (from httpx<1.0.0->datasets!=4.0.*,!=4.1.0,>=3.4.1->unsloth@ git+https://github.com/unslothai/unsloth.git@fc178b5204515ab96dcbced61ea97dc9b9231ab1->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git@fc178b5204515ab96dcbced61ea97dc9b9231ab1) (4.11.0)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.12/dist-packages (from httpx<1.0.0->datasets!=4.0.*,!=4.1.0,>=3.4.1->unsloth@ git+https://github.com/unslothai/unsloth.git@fc178b5204515ab96dcbced61ea97dc9b9231ab1->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git@fc178b5204515ab96dcbced61ea97dc9b9231ab1) (2025.10.5)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.12/dist-packages (from httpx<1.0.0->datasets!=4.0.*,!=4.1.0,>=3.4.1->unsloth@ git+https://github.com/unslothai/unsloth.git@fc178b5204515ab96dcbced61ea97dc9b9231ab1->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git@fc178b5204515ab96dcbced61ea97dc9b9231ab1) (1.0.9)\n",
            "Requirement already satisfied: idna in /usr/local/lib/python3.12/dist-packages (from httpx<1.0.0->datasets!=4.0.*,!=4.1.0,>=3.4.1->unsloth@ git+https://github.com/unslothai/unsloth.git@fc178b5204515ab96dcbced61ea97dc9b9231ab1->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git@fc178b5204515ab96dcbced61ea97dc9b9231ab1) (3.11)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.12/dist-packages (from httpcore==1.*->httpx<1.0.0->datasets!=4.0.*,!=4.1.0,>=3.4.1->unsloth@ git+https://github.com/unslothai/unsloth.git@fc178b5204515ab96dcbced61ea97dc9b9231ab1->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git@fc178b5204515ab96dcbced61ea97dc9b9231ab1) (0.16.0)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests>=2.32.2->datasets!=4.0.*,!=4.1.0,>=3.4.1->unsloth@ git+https://github.com/unslothai/unsloth.git@fc178b5204515ab96dcbced61ea97dc9b9231ab1->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git@fc178b5204515ab96dcbced61ea97dc9b9231ab1) (3.4.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests>=2.32.2->datasets!=4.0.*,!=4.1.0,>=3.4.1->unsloth@ git+https://github.com/unslothai/unsloth.git@fc178b5204515ab96dcbced61ea97dc9b9231ab1->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git@fc178b5204515ab96dcbced61ea97dc9b9231ab1) (2.5.0)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.12/dist-packages (from rich>=11.1.0->tyro->unsloth@ git+https://github.com/unslothai/unsloth.git@fc178b5204515ab96dcbced61ea97dc9b9231ab1->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git@fc178b5204515ab96dcbced61ea97dc9b9231ab1) (4.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.12/dist-packages (from rich>=11.1.0->tyro->unsloth@ git+https://github.com/unslothai/unsloth.git@fc178b5204515ab96dcbced61ea97dc9b9231ab1->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git@fc178b5204515ab96dcbced61ea97dc9b9231ab1) (2.19.2)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch<3,>=2.3->bitsandbytes!=0.46.0,!=0.48.0,>=0.45.5->unsloth@ git+https://github.com/unslothai/unsloth.git@fc178b5204515ab96dcbced61ea97dc9b9231ab1->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git@fc178b5204515ab96dcbced61ea97dc9b9231ab1) (75.2.0)\n",
            "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch<3,>=2.3->bitsandbytes!=0.46.0,!=0.48.0,>=0.45.5->unsloth@ git+https://github.com/unslothai/unsloth.git@fc178b5204515ab96dcbced61ea97dc9b9231ab1->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git@fc178b5204515ab96dcbced61ea97dc9b9231ab1) (1.13.3)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.12/dist-packages (from torch<3,>=2.3->bitsandbytes!=0.46.0,!=0.48.0,>=0.45.5->unsloth@ git+https://github.com/unslothai/unsloth.git@fc178b5204515ab96dcbced61ea97dc9b9231ab1->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git@fc178b5204515ab96dcbced61ea97dc9b9231ab1) (3.5)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch<3,>=2.3->bitsandbytes!=0.46.0,!=0.48.0,>=0.45.5->unsloth@ git+https://github.com/unslothai/unsloth.git@fc178b5204515ab96dcbced61ea97dc9b9231ab1->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git@fc178b5204515ab96dcbced61ea97dc9b9231ab1) (3.1.6)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch<3,>=2.3->bitsandbytes!=0.46.0,!=0.48.0,>=0.45.5->unsloth@ git+https://github.com/unslothai/unsloth.git@fc178b5204515ab96dcbced61ea97dc9b9231ab1->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git@fc178b5204515ab96dcbced61ea97dc9b9231ab1) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch<3,>=2.3->bitsandbytes!=0.46.0,!=0.48.0,>=0.45.5->unsloth@ git+https://github.com/unslothai/unsloth.git@fc178b5204515ab96dcbced61ea97dc9b9231ab1->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git@fc178b5204515ab96dcbced61ea97dc9b9231ab1) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /usr/local/lib/python3.12/dist-packages (from torch<3,>=2.3->bitsandbytes!=0.46.0,!=0.48.0,>=0.45.5->unsloth@ git+https://github.com/unslothai/unsloth.git@fc178b5204515ab96dcbced61ea97dc9b9231ab1->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git@fc178b5204515ab96dcbced61ea97dc9b9231ab1) (12.6.80)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch<3,>=2.3->bitsandbytes!=0.46.0,!=0.48.0,>=0.45.5->unsloth@ git+https://github.com/unslothai/unsloth.git@fc178b5204515ab96dcbced61ea97dc9b9231ab1->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git@fc178b5204515ab96dcbced61ea97dc9b9231ab1) (9.10.2.21)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /usr/local/lib/python3.12/dist-packages (from torch<3,>=2.3->bitsandbytes!=0.46.0,!=0.48.0,>=0.45.5->unsloth@ git+https://github.com/unslothai/unsloth.git@fc178b5204515ab96dcbced61ea97dc9b9231ab1->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git@fc178b5204515ab96dcbced61ea97dc9b9231ab1) (12.6.4.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /usr/local/lib/python3.12/dist-packages (from torch<3,>=2.3->bitsandbytes!=0.46.0,!=0.48.0,>=0.45.5->unsloth@ git+https://github.com/unslothai/unsloth.git@fc178b5204515ab96dcbced61ea97dc9b9231ab1->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git@fc178b5204515ab96dcbced61ea97dc9b9231ab1) (11.3.0.4)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /usr/local/lib/python3.12/dist-packages (from torch<3,>=2.3->bitsandbytes!=0.46.0,!=0.48.0,>=0.45.5->unsloth@ git+https://github.com/unslothai/unsloth.git@fc178b5204515ab96dcbced61ea97dc9b9231ab1->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git@fc178b5204515ab96dcbced61ea97dc9b9231ab1) (10.3.7.77)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /usr/local/lib/python3.12/dist-packages (from torch<3,>=2.3->bitsandbytes!=0.46.0,!=0.48.0,>=0.45.5->unsloth@ git+https://github.com/unslothai/unsloth.git@fc178b5204515ab96dcbced61ea97dc9b9231ab1->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git@fc178b5204515ab96dcbced61ea97dc9b9231ab1) (11.7.1.2)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /usr/local/lib/python3.12/dist-packages (from torch<3,>=2.3->bitsandbytes!=0.46.0,!=0.48.0,>=0.45.5->unsloth@ git+https://github.com/unslothai/unsloth.git@fc178b5204515ab96dcbced61ea97dc9b9231ab1->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git@fc178b5204515ab96dcbced61ea97dc9b9231ab1) (12.5.4.2)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch<3,>=2.3->bitsandbytes!=0.46.0,!=0.48.0,>=0.45.5->unsloth@ git+https://github.com/unslothai/unsloth.git@fc178b5204515ab96dcbced61ea97dc9b9231ab1->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git@fc178b5204515ab96dcbced61ea97dc9b9231ab1) (0.7.1)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.27.3 in /usr/local/lib/python3.12/dist-packages (from torch<3,>=2.3->bitsandbytes!=0.46.0,!=0.48.0,>=0.45.5->unsloth@ git+https://github.com/unslothai/unsloth.git@fc178b5204515ab96dcbced61ea97dc9b9231ab1->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git@fc178b5204515ab96dcbced61ea97dc9b9231ab1) (2.27.3)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch<3,>=2.3->bitsandbytes!=0.46.0,!=0.48.0,>=0.45.5->unsloth@ git+https://github.com/unslothai/unsloth.git@fc178b5204515ab96dcbced61ea97dc9b9231ab1->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git@fc178b5204515ab96dcbced61ea97dc9b9231ab1) (12.6.77)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /usr/local/lib/python3.12/dist-packages (from torch<3,>=2.3->bitsandbytes!=0.46.0,!=0.48.0,>=0.45.5->unsloth@ git+https://github.com/unslothai/unsloth.git@fc178b5204515ab96dcbced61ea97dc9b9231ab1->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git@fc178b5204515ab96dcbced61ea97dc9b9231ab1) (12.6.85)\n",
            "Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /usr/local/lib/python3.12/dist-packages (from torch<3,>=2.3->bitsandbytes!=0.46.0,!=0.48.0,>=0.45.5->unsloth@ git+https://github.com/unslothai/unsloth.git@fc178b5204515ab96dcbced61ea97dc9b9231ab1->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git@fc178b5204515ab96dcbced61ea97dc9b9231ab1) (1.11.1.6)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from pandas->datasets!=4.0.*,!=4.1.0,>=3.4.1->unsloth@ git+https://github.com/unslothai/unsloth.git@fc178b5204515ab96dcbced61ea97dc9b9231ab1->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git@fc178b5204515ab96dcbced61ea97dc9b9231ab1) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas->datasets!=4.0.*,!=4.1.0,>=3.4.1->unsloth@ git+https://github.com/unslothai/unsloth.git@fc178b5204515ab96dcbced61ea97dc9b9231ab1->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git@fc178b5204515ab96dcbced61ea97dc9b9231ab1) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas->datasets!=4.0.*,!=4.1.0,>=3.4.1->unsloth@ git+https://github.com/unslothai/unsloth.git@fc178b5204515ab96dcbced61ea97dc9b9231ab1->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git@fc178b5204515ab96dcbced61ea97dc9b9231ab1) (2025.2)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.9.0,>=2023.1.0->datasets!=4.0.*,!=4.1.0,>=3.4.1->unsloth@ git+https://github.com/unslothai/unsloth.git@fc178b5204515ab96dcbced61ea97dc9b9231ab1->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git@fc178b5204515ab96dcbced61ea97dc9b9231ab1) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.4.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.9.0,>=2023.1.0->datasets!=4.0.*,!=4.1.0,>=3.4.1->unsloth@ git+https://github.com/unslothai/unsloth.git@fc178b5204515ab96dcbced61ea97dc9b9231ab1->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git@fc178b5204515ab96dcbced61ea97dc9b9231ab1) (1.4.0)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.9.0,>=2023.1.0->datasets!=4.0.*,!=4.1.0,>=3.4.1->unsloth@ git+https://github.com/unslothai/unsloth.git@fc178b5204515ab96dcbced61ea97dc9b9231ab1->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git@fc178b5204515ab96dcbced61ea97dc9b9231ab1) (25.4.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.9.0,>=2023.1.0->datasets!=4.0.*,!=4.1.0,>=3.4.1->unsloth@ git+https://github.com/unslothai/unsloth.git@fc178b5204515ab96dcbced61ea97dc9b9231ab1->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git@fc178b5204515ab96dcbced61ea97dc9b9231ab1) (1.8.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.9.0,>=2023.1.0->datasets!=4.0.*,!=4.1.0,>=3.4.1->unsloth@ git+https://github.com/unslothai/unsloth.git@fc178b5204515ab96dcbced61ea97dc9b9231ab1->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git@fc178b5204515ab96dcbced61ea97dc9b9231ab1) (6.7.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.9.0,>=2023.1.0->datasets!=4.0.*,!=4.1.0,>=3.4.1->unsloth@ git+https://github.com/unslothai/unsloth.git@fc178b5204515ab96dcbced61ea97dc9b9231ab1->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git@fc178b5204515ab96dcbced61ea97dc9b9231ab1) (0.4.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.9.0,>=2023.1.0->datasets!=4.0.*,!=4.1.0,>=3.4.1->unsloth@ git+https://github.com/unslothai/unsloth.git@fc178b5204515ab96dcbced61ea97dc9b9231ab1->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git@fc178b5204515ab96dcbced61ea97dc9b9231ab1) (1.22.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.12/dist-packages (from markdown-it-py>=2.2.0->rich>=11.1.0->tyro->unsloth@ git+https://github.com/unslothai/unsloth.git@fc178b5204515ab96dcbced61ea97dc9b9231ab1->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git@fc178b5204515ab96dcbced61ea97dc9b9231ab1) (0.1.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.8.2->pandas->datasets!=4.0.*,!=4.1.0,>=3.4.1->unsloth@ git+https://github.com/unslothai/unsloth.git@fc178b5204515ab96dcbced61ea97dc9b9231ab1->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git@fc178b5204515ab96dcbced61ea97dc9b9231ab1) (1.17.0)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch<3,>=2.3->bitsandbytes!=0.46.0,!=0.48.0,>=0.45.5->unsloth@ git+https://github.com/unslothai/unsloth.git@fc178b5204515ab96dcbced61ea97dc9b9231ab1->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git@fc178b5204515ab96dcbced61ea97dc9b9231ab1) (1.3.0)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.12/dist-packages (from anyio->httpx<1.0.0->datasets!=4.0.*,!=4.1.0,>=3.4.1->unsloth@ git+https://github.com/unslothai/unsloth.git@fc178b5204515ab96dcbced61ea97dc9b9231ab1->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git@fc178b5204515ab96dcbced61ea97dc9b9231ab1) (1.3.1)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch<3,>=2.3->bitsandbytes!=0.46.0,!=0.48.0,>=0.45.5->unsloth@ git+https://github.com/unslothai/unsloth.git@fc178b5204515ab96dcbced61ea97dc9b9231ab1->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git@fc178b5204515ab96dcbced61ea97dc9b9231ab1) (3.0.3)\n",
            "Downloading bitsandbytes-0.48.2-py3-none-manylinux_2_24_x86_64.whl (59.4 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m59.4/59.4 MB\u001b[0m \u001b[31m45.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading datasets-4.3.0-py3-none-any.whl (506 kB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m506.8/506.8 kB\u001b[0m \u001b[31m46.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading transformers-4.56.2-py3-none-any.whl (11.6 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m11.6/11.6 MB\u001b[0m \u001b[31m103.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading unsloth_zoo-2025.10.12-py3-none-any.whl (272 kB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m272.2/272.2 kB\u001b[0m \u001b[31m28.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tyro-0.9.35-py3-none-any.whl (132 kB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m132.6/132.6 kB\u001b[0m \u001b[31m15.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pyarrow-22.0.0-cp312-cp312-manylinux_2_28_x86_64.whl (47.7 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m47.7/47.7 MB\u001b[0m \u001b[31m56.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading shtab-1.7.2-py3-none-any.whl (14 kB)\n",
            "Downloading torchao-0.14.1-cp310-abi3-manylinux_2_24_x86_64.manylinux_2_28_x86_64.whl (7.2 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m7.2/7.2 MB\u001b[0m \u001b[31m65.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading trl-0.23.0-py3-none-any.whl (564 kB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m564.7/564.7 kB\u001b[0m \u001b[31m48.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading cut_cross_entropy-25.1.1-py3-none-any.whl (22 kB)\n",
            "Downloading msgspec-0.19.0-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (213 kB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m213.6/213.6 kB\u001b[0m \u001b[31m22.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hBuilding wheels for collected packages: unsloth\n",
            "  Building wheel for unsloth (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for unsloth: filename=unsloth-2025.10.10-py3-none-any.whl size=349946 sha256=c75acf8c5c51246fd2f5b0dcc2ae6bfb7743b16c2e075446f10dd35d64498365\n",
            "  Stored in directory: /root/.cache/pip/wheels/a9/ee/88/5aded5f7f4bf11e827a41659ac742a7a9d6b7b35986b3eac37\n",
            "Successfully built unsloth\n",
            "Installing collected packages: torchao, unsloth, shtab, pyarrow, msgspec, tyro, transformers, datasets, cut_cross_entropy, bitsandbytes, trl, unsloth_zoo\n",
            "  Attempting uninstall: torchao\n",
            "    Found existing installation: torchao 0.10.0\n",
            "    Uninstalling torchao-0.10.0:\n",
            "      Successfully uninstalled torchao-0.10.0\n",
            "  Attempting uninstall: pyarrow\n",
            "    Found existing installation: pyarrow 18.1.0\n",
            "    Uninstalling pyarrow-18.1.0:\n",
            "      Successfully uninstalled pyarrow-18.1.0\n",
            "  Attempting uninstall: transformers\n",
            "    Found existing installation: transformers 4.57.1\n",
            "    Uninstalling transformers-4.57.1:\n",
            "      Successfully uninstalled transformers-4.57.1\n",
            "  Attempting uninstall: datasets\n",
            "    Found existing installation: datasets 4.0.0\n",
            "    Uninstalling datasets-4.0.0:\n",
            "      Successfully uninstalled datasets-4.0.0\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "cudf-cu12 25.6.0 requires pyarrow<20.0.0a0,>=14.0.0; platform_machine == \"x86_64\", but you have pyarrow 22.0.0 which is incompatible.\n",
            "pylibcudf-cu12 25.6.0 requires pyarrow<20.0.0a0,>=14.0.0; platform_machine == \"x86_64\", but you have pyarrow 22.0.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed bitsandbytes-0.48.2 cut_cross_entropy-25.1.1 datasets-4.3.0 msgspec-0.19.0 pyarrow-22.0.0 shtab-1.7.2 torchao-0.14.1 transformers-4.56.2 trl-0.23.0 tyro-0.9.35 unsloth-2025.10.10 unsloth_zoo-2025.10.12\n",
            "Collecting xformers<0.0.26\n",
            "  Downloading xformers-0.0.25.post1.tar.gz (4.1 MB)\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m4.1/4.1 MB\u001b[0m \u001b[31m80.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting trl<0.9.0\n",
            "  Downloading trl-0.8.6-py3-none-any.whl.metadata (11 kB)\n",
            "Collecting peft<0.12.0\n",
            "  Downloading peft-0.11.1-py3-none-any.whl.metadata (13 kB)\n",
            "Collecting accelerate<0.32.0\n",
            "  Downloading accelerate-0.31.0-py3-none-any.whl.metadata (19 kB)\n",
            "Collecting bitsandbytes<0.44.0\n",
            "  Downloading bitsandbytes-0.43.3-py3-none-manylinux_2_24_x86_64.whl.metadata (3.5 kB)\n",
            "Collecting transformers<4.43.0\n",
            "  Downloading transformers-4.42.4-py3-none-any.whl.metadata (43 kB)\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m43.6/43.6 kB\u001b[0m \u001b[31m4.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading trl-0.8.6-py3-none-any.whl (245 kB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m245.2/245.2 kB\u001b[0m \u001b[31m25.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading peft-0.11.1-py3-none-any.whl (251 kB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m251.6/251.6 kB\u001b[0m \u001b[31m30.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading accelerate-0.31.0-py3-none-any.whl (309 kB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m309.4/309.4 kB\u001b[0m \u001b[31m35.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading bitsandbytes-0.43.3-py3-none-manylinux_2_24_x86_64.whl (137.5 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m137.5/137.5 MB\u001b[0m \u001b[31m15.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading transformers-4.42.4-py3-none-any.whl (9.3 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m9.3/9.3 MB\u001b[0m \u001b[31m127.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hBuilding wheels for collected packages: xformers\n",
            "  Building wheel for xformers (setup.py) ... \u001b[?25l\u001b[?25hcanceled\u001b[31mERROR: Operation cancelled by user\u001b[0m\u001b[31m\n",
            "\u001b[0m"
          ]
        }
      ],
      "source": [
        "!pip install -U \"unsloth[colab-new] @ git+https://github.com/unslothai/unsloth.git@fc178b5204515ab96dcbced61ea97dc9b9231ab1 \"\n",
        "!pip install --no-deps \"xformers<0.0.26\" \"trl<0.9.0\" \"peft<0.12.0\" \"accelerate<0.32.0\" \"bitsandbytes<0.44.0\" \"transformers<4.43.0\"\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "_a1LqBektD6x",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 353,
          "referenced_widgets": [
            "b2acba9e05c9486c8680038037aabce1",
            "099634a5cddc46e28ed42079d490d894",
            "77d20e3738014ff2a1dcd09fdbcf1ae4",
            "dd927f8e728c4dafbdcd4615e502ab4a",
            "268cf0e99b0e41ce931b7d4ff977d371",
            "bfd8827b1eeb47359b5ed0dbbea7fda4",
            "1d8fa656c79a4592a784ae7a7dcf7fde",
            "5661367b8b144a51b63c26ae0a836246",
            "bc78deef344f4218b2f67a344c14c6e1",
            "0b85c31e6ea941659c0705e171b4e3e8",
            "2d1246caa32f4061bd9abc8b5290cafb",
            "0572d2a178824f57ba24ef5013533d1b",
            "eabc758b0dc543e6bf93934340d8e45c",
            "7272a780647c441484fb7bf1ca2b265d",
            "90956e6c2aaf4b449c75b15784e54024",
            "31a2b1a759fa485aab50cac38b4a08e7",
            "b888206318e6476eaddbe0a42d08b601",
            "34baab48c29b47c198c6b1c385b36227",
            "22ff034d0c93476fb2a9a71a5d850267",
            "01d59e57bfdf46fe9d4fc8918490e8cc",
            "fe69663933aa4aefa37e26d0de759857",
            "41f10aa7802c4b7e8cedff513835c9f1",
            "4021719b7328416c98f230ac15d0c02d",
            "ca3b313e9f7d497184cfe4109c43b070",
            "818b3409a55b447aa0f90f5b6833b5b7",
            "59e878991f534bb1bb2203e35e70fb1a",
            "d8c0d8a48f4344829fd5b90ecca22d68",
            "8269587cc0144a52bbed71ceaab02c88",
            "21374658b3e34a35bcc97192d689bdf1",
            "8cebb08351de4f84a14ae188b5082b7f",
            "4ec5cc77b9f546fc970cac62b5e244ce",
            "d1e884cdd3244b3fbf0494c44357fd4d",
            "c5a0e11c67364cae9993348327238e52",
            "4f7b2a8eb4ea4af180828a15d6638341",
            "865bc78774e34d019747e8f836cda529",
            "dbeef1e7718b49ffa0baab44e2662c04",
            "51ef695ef99549eab7e6e79f905b2356",
            "ff4b57b3ec3d437ea7107d47caedb425",
            "02e3fde682244403be5a4515b3c1e736",
            "2069b440cd2b41bdb3eb6d897530213e",
            "8bc32cfe5e47440ca3a5ba30141eb091",
            "d936068254104d40b11cb7724b2727da",
            "6960a88e4d414c79ae74a97303c6ad7c",
            "c6fddb5aae4e437e9cd681e85c34f08d",
            "e3a2b4a215364a738f00030df9f63519",
            "f41a023018ce43658f51d72d1aa21ea8",
            "f30ea5c55089499fb6e8ada370b0b914",
            "0b5c1413e0ff4be0b1ba7e64e197ff73",
            "d7e2fc6e75504a12abf59806457c74e1",
            "0afa92f7c2bc4990acd51dfe108369e6",
            "0c672cf0ba6b4b99964ae11d5602bffe",
            "2b6fc10516b74a7a8c9f1bb835190d10",
            "4ccc8c62ad4f4e76a34b2f847445a75e",
            "41d8425d8ce44026a8681cf877168e46",
            "882a529d50f84a4c8ad5d50680cef08a"
          ]
        },
        "outputId": "88238e49-759f-490e-f66c-f65c4852be2a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ğŸ¦¥ Unsloth: Will patch your computer to enable 2x faster free finetuning.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:torchao:Skipping import of cpp extensions due to incompatible torch version 2.8.0+cu126 for torchao version 0.14.1             Please see https://github.com/pytorch/ao/issues/2919 for more info\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ğŸ¦¥ Unsloth Zoo will now patch everything to make training faster!\n",
            "==((====))==  Unsloth 2025.10.10: Fast Llama patching. Transformers: 4.56.2.\n",
            "   \\\\   /|    NVIDIA A100-SXM4-80GB. Num GPUs = 1. Max memory: 79.318 GB. Platform: Linux.\n",
            "O^O/ \\_/ \\    Torch: 2.8.0+cu126. CUDA: 8.0. CUDA Toolkit: 12.6. Triton: 3.4.0\n",
            "\\        /    Bfloat16 = TRUE. FA [Xformers = None. FA2 = False]\n",
            " \"-____-\"     Free license: http://github.com/unslothai/unsloth\n",
            "Unsloth: Fast downloading is enabled - ignore downloading bars which are red colored!\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model.safetensors:   0%|          | 0.00/5.96G [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "b2acba9e05c9486c8680038037aabce1"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "generation_config.json:   0%|          | 0.00/235 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "0572d2a178824f57ba24ef5013533d1b"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer_config.json: 0.00B [00:00, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "4021719b7328416c98f230ac15d0c02d"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "special_tokens_map.json:   0%|          | 0.00/459 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "4f7b2a8eb4ea4af180828a15d6638341"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer.json:   0%|          | 0.00/17.2M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "e3a2b4a215364a738f00030df9f63519"
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "from unsloth import FastLanguageModel\n",
        "import torch\n",
        "\n",
        "max_seq_length = 1024\n",
        "dtype = None\n",
        "load_in_4bit = True\n",
        "\n",
        "model, tokenizer = FastLanguageModel.from_pretrained(\n",
        "    model_name = \"unsloth/Meta-Llama-3.1-8B\",\n",
        "    max_seq_length = max_seq_length,\n",
        "    dtype = dtype,\n",
        "    load_in_4bit = load_in_4bit,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "w-1_gGYJtpnA",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 293,
          "referenced_widgets": [
            "602d8a83624c47fb9eb8f1b6ca396a4a",
            "388554b55a5a48e89e5886e04bfae0ee",
            "ee0b503b0bf54cdb845839fc99448696",
            "4d2a29c38c924c30a542aff7aa839f91",
            "3c293c9fd0134d41b80df5e7140f9c0d",
            "ee7c8873a406479abe2eb0bad4ee5eb2",
            "591aead417694bf49c2975437e2da438",
            "239e5dfadbb14f6ca219bee9bd75f1e2",
            "ac1de33a90e742c39769237748c29db0",
            "e228601c789e42cd9970f9efe39e30d4",
            "0c5ec5f3f0144ad484d3868006b85615",
            "6cd99c04f235408db38391c3b9216c91",
            "093e065fdc9f4f56aeae6334d16dc7c5",
            "8280951d7c334fe9940a254fa12b6b08",
            "394ab6da10754605ac1e1befb313677a",
            "d196c344721d4b34930bb8214a688050",
            "a8f7e5585eaf4c2fa8d70405e61ae6fa",
            "9af403d14aa640f983f62fb586d18a9b",
            "c56da126b9fc4c328b993e1d8428b6a2",
            "30a02c0b81dd4dd187374fbfc8dc2193",
            "4b5c84168c3c480496011a3264a14a7a",
            "6ba5cab3c106422f973c2a76c44898b9",
            "5a5b794a583a42968a17771aa502be66",
            "0e61c6ec71884adca1ba23bd729f76ce",
            "6d347283ec474cc7b5d601467be1343a",
            "c885e741e9ff4d28a552b41c75aee1af",
            "a4604f6fbe7c4c85bf0742654c9a5bd0",
            "62e473b5ed3e4aa2916c435b674aa676",
            "2e4f34d2eba44a5cb2220a9db4cff8a3",
            "01c1d8eea1104c49ad38089d50c991bd",
            "444bcb4480484db8afd00413790f7a9b",
            "adb61a99fc594f6d8b2caa67cbb28041",
            "3d4c2f2ad163477f88213a63065b59bd",
            "c40f159908c14a37b79442a65664c9d6",
            "86549c7fcddd4694a7b10d03faff198e",
            "d4f2f932ac1c426892f3afbb6a8768a2",
            "8d4b82f557764aeaab6bd67cadbc7827",
            "d4bd7f901dc942d981b1dd0748d42955",
            "2e3af6635868474dafae26c048b32fa3",
            "c025c3d9bc4c4a9397f1a6b77c16594f",
            "52ad79d80fe348f18013a00f4b1890f2",
            "ceae2a160e9c40b784a9b3897f1c6540",
            "a2eaa16f3ef545ee97246036ee316301",
            "65ce4ff5e6a44d7cbb61647e4f347891",
            "47140db9af114c27ad709d69f64cb150",
            "0f1fc036ed664a8782b35de0fd4b870b",
            "39589ad182784d4aa3e6ff9a88c39c15",
            "b92276d9119c4adf8cff85253b4bf778",
            "5e6b65887805463ca6086aac00f6bb17",
            "e210eab51beb48b4aef8639334db164b",
            "5378d4cc68df45d1a206d1451cf7d624",
            "a81fc82a264247db94c78561bfcf6daa",
            "b2a481cf2e154b76a09c697b91c3fac3",
            "ea8801916a5b424181427bce1539c0b5",
            "be833b8bc45b4ab6a90221660bab3652",
            "ea9f18f6a1ca4daca7af3934b803d4ad",
            "ca13d866000e404a9ab707f362495c8b",
            "1600119cf7de4351a36256d19517c530",
            "655e6ead77a449b99ffc654c03115772",
            "87d0f04c34fb4b88b741a69745f6f677",
            "a62c6e4710ba4b17b317a507872ea4d2",
            "185a8f2a2f954511b47397a883a0165b",
            "68c5a6c27e6d4993bdfe4e7ed9579350",
            "b770517c7c4a4593a65ac0e29a93a905",
            "8e6918a37bed4ee2bb2c068037d06ef7",
            "58ab7a4a3e2340a39b8a669e32ece967"
          ]
        },
        "outputId": "d2ca12cb-8afc-4247-ac4f-9a457acf6f58"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "README.md: 0.00B [00:00, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "602d8a83624c47fb9eb8f1b6ca396a4a"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "data/train-00000-of-00002.parquet:   0%|          | 0.00/195M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "6cd99c04f235408db38391c3b9216c91"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "data/train-00001-of-00002.parquet:   0%|          | 0.00/195M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "5a5b794a583a42968a17771aa502be66"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "data/test-00000-of-00001.parquet:   0%|          | 0.00/3.65M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "c40f159908c14a37b79442a65664c9d6"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Generating train split:   0%|          | 0/1000000 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "47140db9af114c27ad709d69f64cb150"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Generating test split:   0%|          | 0/10000 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "ea9f18f6a1ca4daca7af3934b803d4ad"
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "from datasets import load_dataset\n",
        "\n",
        "# Load the full training dataset\n",
        "full_dataset = load_dataset(\"ad6398/nyu-dl-teach-maths-comp\", split=\"train\")\n",
        "\n",
        "# Shuffle the dataset for randomness and create our smaller splits\n",
        "shuffled_dataset = full_dataset.shuffle(seed=42)\n",
        "train_dataset = shuffled_dataset.select(range(8000))\n",
        "validation_dataset = shuffled_dataset.select(range(8000, 8200))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "XSvAKd3nt5DA",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 81,
          "referenced_widgets": [
            "94830cb204134acbbcfd78e707361728",
            "fcbf06fc8875430482df6d317b28d1ef",
            "60a5b7b2394c43e38b5d9cd2e8efba30",
            "724d2b5a71814c4fb57faf1ca69fdfb5",
            "7848322284a34008a84ab4b8ddc0c083",
            "68e29f775b5249c19fa95aa84bb6e090",
            "2a0e2c69f93f4824aa03fe4087d979cb",
            "ca2ce6b19a294a14ab2659474a6e4d31",
            "da3cf0335a3d4aa48523ce0aa95fc6c3",
            "8c0a7424193049d8aac10eece6c3af51",
            "677a28aa2e6b40bca1f234819c441d11",
            "1ad9100563f74c8281f89361d4fb8b68",
            "f8048b281bd44221a303372dd758ba40",
            "8b508b150da94a769c37dac9529d5039",
            "231e03d077cb49a39e6f52a633f89ee6",
            "dcb45b28fb4044c8890348f44201a722",
            "df53fe22fb80421dba3d07cfc784b2f0",
            "16e2758ad926468d95ac2fb9fc6bfbf1",
            "99a21a2ff2d84a78bebaba2cc8375607",
            "c5edea0711934df597f7a3a8c863777d",
            "56519c0c4d3a466b9472182498f78dff",
            "948cdfc31829419da73f6b7679c56ebb"
          ]
        },
        "outputId": "da531c9b-08c1-4da4-dec4-3772415629fe"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Map:   0%|          | 0/8000 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "94830cb204134acbbcfd78e707361728"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Map:   0%|          | 0/200 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "1ad9100563f74c8281f89361d4fb8b68"
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "# The instructional prompt template for training\n",
        "training_prompt = \"\"\"You are a great mathematician and you are tasked with finding if a solution to a given maths question is correct or not. Carefully analyze each step of the provided solution and determine if it is correct. Your response should be 'True' if the solution is correct, otherwise 'False'. Below is the Question and Solution.\n",
        "Question:\n",
        "{}\n",
        "Solution:\n",
        "{}\n",
        "Reasoning and Verification:\n",
        "{}\n",
        "Output:\n",
        "{}\"\"\"\n",
        "\n",
        "# We must add an End Of Sequence (EOS) token to tell the model when a completion is finished.\n",
        "EOS_TOKEN = tokenizer.eos_token\n",
        "\n",
        "# This function formats our data samples into the prompt template.\n",
        "def formatting_prompts_func(examples):\n",
        "    questions = examples[\"question\"]\n",
        "    solutions = examples[\"solution\"]\n",
        "    outputs = examples[\"is_correct\"]\n",
        "    texts = []\n",
        "    for question, solution, output in zip(questions, solutions, outputs):\n",
        "        # Format the prompt and add the EOS token\n",
        "        reasoning_placeholder = \"\"\n",
        "        text = training_prompt.format(question, str(solution), reasoning_placeholder, str(output)) + EOS_TOKEN\n",
        "        texts.append(text)\n",
        "    return { \"text\" : texts }\n",
        "\n",
        "# Apply the formatting function to our training dataset\n",
        "formatted_train_dataset = train_dataset.map(formatting_prompts_func, batched=True, load_from_cache_file=False,)\n",
        "formatted_val_dataset = validation_dataset.map(formatting_prompts_func, batched=True, load_from_cache_file=False,)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "2ZkCRtgvuJXI",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a318a296-9d9e-4f4b-fca2-acabcc3658e2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Unsloth: Dropout = 0 is supported for fast patching. You are using dropout = 0.1.\n",
            "Unsloth will patch all other layers, except LoRA matrices, causing a performance hit.\n",
            "Unsloth 2025.10.10 patched 32 layers with 0 QKV layers, 0 O layers and 0 MLP layers.\n"
          ]
        }
      ],
      "source": [
        "model = FastLanguageModel.get_peft_model(\n",
        "    model,\n",
        "    r = 32,\n",
        "    target_modules = [\"q_proj\", \"k_proj\", \"v_proj\", \"o_proj\",\n",
        "                      \"gate_proj\", \"up_proj\", \"down_proj\"],\n",
        "    lora_alpha = 64,\n",
        "    lora_dropout = 0.1,\n",
        "    bias = \"none\",\n",
        "    use_gradient_checkpointing = \"unsloth\",\n",
        "    random_state = 42,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "AbkQ0IBTyh-o",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 81,
          "referenced_widgets": [
            "7a68dd0cf4934d31be7a45bb13658d0a",
            "03f055788967400a9a71d80f09a819e0",
            "fbe8296b299b4b8f9afc5ea5bec2700c",
            "79db0feb5cb1458a9e67b60e82ae14ac",
            "77b6f6bb88894336b67e3ced18a88298",
            "e5849c39841c4b198f78117d0a946d9a",
            "31c8ee5c17954d92aae9a9ae6a7e62f0",
            "01aa9f5c84224bda9359781213cfa907",
            "67c200d624434a2baac9dfbb4d8235ab",
            "ca293d964f02432a91935ac36e06e8fb",
            "c57962b9418141659b6fd2c5bec1a0fc",
            "8f0cf076c44e4fe4a7327037d7c39631",
            "2db464945a6b4479a152fe2cfe394ccd",
            "101503cd9ced45d89311c07cdfa452a7",
            "0f0e2c0932604cbb9c819ec33bf2d8bd",
            "4716b53b89ff428c8096bf70e9c392ab",
            "80bf20da57564562a5acafd19d22993d",
            "8d7121cc3aba4faca82b107b03222cfb",
            "626c830697a1404ba229167f1b3fdf1b",
            "7a18136d3ce1450bb1477cedaac273dd",
            "a4c8fcb7c92b44baa2f3e288328e9d2d",
            "0ef143824192495fae21b29b39e384f5"
          ]
        },
        "outputId": "63b420c0-cfcd-4f91-cdb9-01179f8187cf"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Unsloth: Tokenizing [\"text\"] (num_proc=16):   0%|          | 0/8000 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "7a68dd0cf4934d31be7a45bb13658d0a"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Unsloth: Tokenizing [\"text\"] (num_proc=16):   0%|          | 0/200 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "8f0cf076c44e4fe4a7327037d7c39631"
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "from trl import SFTTrainer\n",
        "from transformers import TrainingArguments, EarlyStoppingCallback\n",
        "\n",
        "trainer = SFTTrainer(\n",
        "    model = model,\n",
        "    tokenizer = tokenizer,\n",
        "    train_dataset = formatted_train_dataset,\n",
        "    eval_dataset = formatted_val_dataset,\n",
        "    dataset_text_field = \"text\",\n",
        "    max_seq_length = max_seq_length,\n",
        "    callbacks = [EarlyStoppingCallback(early_stopping_patience = 6)],\n",
        "    args = TrainingArguments(\n",
        "        per_device_train_batch_size=2,\n",
        "        gradient_accumulation_steps=8,\n",
        "        num_train_epochs=5,\n",
        "        learning_rate=1e-4,\n",
        "        weight_decay=0.01,\n",
        "        logging_steps=10,\n",
        "        eval_strategy=\"steps\",\n",
        "        eval_steps=100,\n",
        "        save_strategy=\"steps\",\n",
        "        save_steps=200,\n",
        "        load_best_model_at_end=True,\n",
        "        metric_for_best_model=\"eval_loss\",\n",
        "        greater_is_better=False,\n",
        "        warmup_ratio = 0.05,\n",
        "        lr_scheduler_type=\"cosine_with_restarts\",\n",
        "        prediction_loss_only=True,\n",
        "        include_inputs_for_metrics=False,\n",
        "        eval_accumulation_steps=4,\n",
        "        per_device_eval_batch_size=4,\n",
        "        dataloader_pin_memory=False,\n",
        "        dataloader_drop_last=True,\n",
        "        fp16 = not torch.cuda.is_bf16_supported(),\n",
        "        bf16 = torch.cuda.is_bf16_supported(),\n",
        "        optim = \"adamw_8bit\",\n",
        "        seed = 42,\n",
        "        output_dir = \"/content/drive/MyDrive/llama3_8b_math_verifier_checkpointv2\",\n",
        "        save_total_limit=2,\n",
        "        report_to = \"none\",\n",
        "    ),\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "collapsed": true,
        "id": "UvZeXNck2x1S",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 803
        },
        "outputId": "b7e5f69d-2ad0-4370-ef90-b4ea3a88fa63"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "==((====))==  Unsloth - 2x faster free finetuning | Num GPUs used = 1\n",
            "   \\\\   /|    Num examples = 8,000 | Num Epochs = 5 | Total steps = 2,500\n",
            "O^O/ \\_/ \\    Batch size per device = 2 | Gradient accumulation steps = 8\n",
            "\\        /    Data Parallel GPUs = 1 | Total batch size (2 x 8 x 1) = 16\n",
            " \"-____-\"     Trainable parameters = 83,886,080 of 8,114,147,328 (1.03% trained)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Unsloth: Will smartly offload gradients to save VRAM!\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='1600' max='2500' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [1600/2500 2:07:47 < 1:11:58, 0.21 it/s, Epoch 3/5]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>100</td>\n",
              "      <td>0.684200</td>\n",
              "      <td>0.651755</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>200</td>\n",
              "      <td>0.643800</td>\n",
              "      <td>0.634204</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>300</td>\n",
              "      <td>0.663800</td>\n",
              "      <td>0.626065</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>400</td>\n",
              "      <td>0.639100</td>\n",
              "      <td>0.616716</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>500</td>\n",
              "      <td>0.634800</td>\n",
              "      <td>0.612404</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>600</td>\n",
              "      <td>0.529900</td>\n",
              "      <td>0.616413</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>700</td>\n",
              "      <td>0.548900</td>\n",
              "      <td>0.606942</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>800</td>\n",
              "      <td>0.516400</td>\n",
              "      <td>0.606023</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>900</td>\n",
              "      <td>0.524100</td>\n",
              "      <td>0.599219</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1000</td>\n",
              "      <td>0.549400</td>\n",
              "      <td>0.591439</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1100</td>\n",
              "      <td>0.393400</td>\n",
              "      <td>0.618575</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1200</td>\n",
              "      <td>0.395300</td>\n",
              "      <td>0.621385</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1300</td>\n",
              "      <td>0.480300</td>\n",
              "      <td>0.607999</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1400</td>\n",
              "      <td>0.382800</td>\n",
              "      <td>0.611064</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1500</td>\n",
              "      <td>0.388300</td>\n",
              "      <td>0.608509</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1600</td>\n",
              "      <td>0.276600</td>\n",
              "      <td>0.669302</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Unsloth: Not an error, but LlamaForCausalLM does not accept `num_items_in_batch`.\n",
            "Using gradient accumulation will be very slightly less accurate.\n",
            "Read more on gradient accumulation issues here: https://unsloth.ai/blog/gradient\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TrainOutput(global_step=1600, training_loss=0.5276304449141026, metrics={'train_runtime': 7679.5399, 'train_samples_per_second': 5.209, 'train_steps_per_second': 0.326, 'total_flos': 4.4189089507948954e+17, 'train_loss': 0.5276304449141026, 'epoch': 3.2})"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ],
      "source": [
        "trainer.train()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')\n",
        "\n",
        "import os\n",
        "\n",
        "# Define the path to save the model checkpoint in Google Drive\n",
        "save_path = \"/content/gdrive/MyDrive/llama3_8b_math_verifier_checkpointv2\"\n",
        "\n",
        "# Create the directory if it doesn't exist\n",
        "os.makedirs(save_path, exist_ok=True)\n",
        "\n",
        "# Save the model and tokenizer\n",
        "model.save_pretrained(save_path)\n",
        "tokenizer.save_pretrained(save_path)\n",
        "\n",
        "print(f\"Model checkpoint and tokenizer saved to: {save_path}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XOCojFW2WGVb",
        "outputId": "822423af-0c0c-41ca-f339-48853ce4c641"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n",
            "Model checkpoint and tokenizer saved to: /content/gdrive/MyDrive/llama3_8b_math_verifier_checkpointv2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "agvQR_Ku5wWY",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ebe161e0-b566-4fd6-f028-f92fe97859a0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "#### QUESTION ####\n",
            "Lily has $3$ gallons of milk and gives $\\frac{12}{5}$ gallons to James. What fraction of a gallon does she have left?\n",
            "\n",
            "#### SOLUTION ####\n",
            "Let's use Python's sympy library to solve this arithmetic problem.\n",
            "<llm-code>\n",
            "from sympy import Rational\n",
            "\n",
            "# Define the amount of milk Lily has and the amount she gives to James\n",
            "lily_milk = 3\n",
            "james_milk = Rational(12,5)\n",
            "\n",
            "# Calculate the fraction of milk Lily has left\n",
            "lily_left = lily_milk - james_milk\n",
            "\n",
            "print(lily_left)\n",
            "</llm-code>\n",
            "<llm-code-output>\n",
            "3/5\n",
            "</llm-code-output>\n",
            "So Lily has $\\boxed{\\frac{3}{5}}$ of a gallon left.\n",
            "\n",
            "#### MODEL'S PREDICTION ####\n",
            "True<|end_of_text|>\n",
            "\n",
            "#### CORRECT ANSWER ####\n",
            "True\n"
          ]
        }
      ],
      "source": [
        "# Prepare the model for faster inference\n",
        "FastLanguageModel.for_inference(model)\n",
        "\n",
        "# Create the prompt template for inference (no answer included)\n",
        "inference_prompt = \"\"\"You are a great mathematician and you are tasked with finding if a solution to a given maths question is correct or not. Carefully analyze each step of the provided solution and determine if it is correct. Your response should be 'True' if the solution is correct, otherwise 'False'. Below is the Question and Solution.\n",
        "Question:\n",
        "{}\n",
        "Solution:\n",
        "{}\n",
        "Reasoning and Verification:\n",
        "Output:\n",
        "\"\"\"\n",
        "\n",
        "# Select a sample from the validation set\n",
        "example = validation_dataset[10] # You can change the index (e.g., to 1, 2, 50)\n",
        "question = example[\"question\"]\n",
        "solution = example[\"solution\"]\n",
        "\n",
        "# Format the prompt with the validation data\n",
        "inference_text = inference_prompt.format(question, solution)\n",
        "inputs = tokenizer([inference_text], return_tensors=\"pt\").to(\"cuda\")\n",
        "\n",
        "# Generate the model's response\n",
        "outputs = model.generate(**inputs,max_new_tokens=64,do_sample=False,temperature=0,use_cache=True)\n",
        "response = tokenizer.batch_decode(outputs)\n",
        "\n",
        "# Print the results\n",
        "print(\"#### QUESTION ####\")\n",
        "print(question)\n",
        "print(\"\\n#### SOLUTION ####\")\n",
        "print(solution)\n",
        "print(\"\\n#### MODEL'S PREDICTION ####\")\n",
        "# We process the output to show only the generated text\n",
        "print(response[0].split(\"Output:\\n\")[1])\n",
        "print(\"\\n#### CORRECT ANSWER ####\")\n",
        "print(example[\"is_correct\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "usxFKb0CJEQ8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 801
        },
        "outputId": "8bd8107c-03e8-4cc8-8512-d65ce72beb49"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 11%|â–ˆ         | 1064/10000 [04:44<40:00,  3.72it/s]Unsloth: Input IDs of shape torch.Size([1, 1050]) with length 1050 > the model's max sequence length of 1024.\n",
            "We shall truncate it ourselves. It's imperative if you correct this issue first.\n",
            " 13%|â–ˆâ–        | 1274/10000 [05:40<39:13,  3.71it/s]Unsloth: Input IDs of shape torch.Size([1, 1218]) with length 1218 > the model's max sequence length of 1024.\n",
            "We shall truncate it ourselves. It's imperative if you correct this issue first.\n",
            " 16%|â–ˆâ–Œ        | 1572/10000 [07:05<37:33,  3.74it/s]Unsloth: Input IDs of shape torch.Size([1, 1059]) with length 1059 > the model's max sequence length of 1024.\n",
            "We shall truncate it ourselves. It's imperative if you correct this issue first.\n",
            " 16%|â–ˆâ–Œ        | 1590/10000 [07:10<37:23,  3.75it/s]Unsloth: Input IDs of shape torch.Size([1, 1031]) with length 1031 > the model's max sequence length of 1024.\n",
            "We shall truncate it ourselves. It's imperative if you correct this issue first.\n",
            " 23%|â–ˆâ–ˆâ–       | 2329/10000 [10:28<34:09,  3.74it/s]Unsloth: Input IDs of shape torch.Size([1, 1232]) with length 1232 > the model's max sequence length of 1024.\n",
            "We shall truncate it ourselves. It's imperative if you correct this issue first.\n",
            " 30%|â–ˆâ–ˆâ–ˆ       | 3050/10000 [13:44<30:57,  3.74it/s]Unsloth: Input IDs of shape torch.Size([1, 1277]) with length 1277 > the model's max sequence length of 1024.\n",
            "We shall truncate it ourselves. It's imperative if you correct this issue first.\n",
            " 33%|â–ˆâ–ˆâ–ˆâ–      | 3251/10000 [14:41<29:40,  3.79it/s]Unsloth: Input IDs of shape torch.Size([1, 1071]) with length 1071 > the model's max sequence length of 1024.\n",
            "We shall truncate it ourselves. It's imperative if you correct this issue first.\n",
            " 33%|â–ˆâ–ˆâ–ˆâ–      | 3321/10000 [15:03<29:38,  3.76it/s]Unsloth: Input IDs of shape torch.Size([1, 1172]) with length 1172 > the model's max sequence length of 1024.\n",
            "We shall truncate it ourselves. It's imperative if you correct this issue first.\n",
            " 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 3547/10000 [16:07<28:36,  3.76it/s]Unsloth: Input IDs of shape torch.Size([1, 1327]) with length 1327 > the model's max sequence length of 1024.\n",
            "We shall truncate it ourselves. It's imperative if you correct this issue first.\n",
            " 40%|â–ˆâ–ˆâ–ˆâ–‰      | 3988/10000 [18:10<26:58,  3.71it/s]Unsloth: Input IDs of shape torch.Size([1, 1082]) with length 1082 > the model's max sequence length of 1024.\n",
            "We shall truncate it ourselves. It's imperative if you correct this issue first.\n",
            " 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 4584/10000 [20:53<24:18,  3.71it/s]Unsloth: Input IDs of shape torch.Size([1, 1084]) with length 1084 > the model's max sequence length of 1024.\n",
            "We shall truncate it ourselves. It's imperative if you correct this issue first.\n",
            " 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 5412/10000 [24:38<20:28,  3.74it/s]Unsloth: Input IDs of shape torch.Size([1, 1341]) with length 1341 > the model's max sequence length of 1024.\n",
            "We shall truncate it ourselves. It's imperative if you correct this issue first.\n",
            " 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 5943/10000 [27:04<18:32,  3.65it/s]Unsloth: Input IDs of shape torch.Size([1, 1206]) with length 1206 > the model's max sequence length of 1024.\n",
            "We shall truncate it ourselves. It's imperative if you correct this issue first.\n",
            " 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 6441/10000 [29:20<15:54,  3.73it/s]Unsloth: Input IDs of shape torch.Size([1, 1097]) with length 1097 > the model's max sequence length of 1024.\n",
            "We shall truncate it ourselves. It's imperative if you correct this issue first.\n",
            " 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 6559/10000 [29:55<15:08,  3.79it/s]Unsloth: Input IDs of shape torch.Size([1, 1290]) with length 1290 > the model's max sequence length of 1024.\n",
            "We shall truncate it ourselves. It's imperative if you correct this issue first.\n",
            " 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 6620/10000 [30:16<14:55,  3.77it/s]Unsloth: Input IDs of shape torch.Size([1, 1255]) with length 1255 > the model's max sequence length of 1024.\n",
            "We shall truncate it ourselves. It's imperative if you correct this issue first.\n",
            " 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 7763/10000 [35:24<09:53,  3.77it/s]Unsloth: Input IDs of shape torch.Size([1, 1052]) with length 1052 > the model's max sequence length of 1024.\n",
            "We shall truncate it ourselves. It's imperative if you correct this issue first.\n",
            " 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 7964/10000 [36:20<08:57,  3.79it/s]Unsloth: Input IDs of shape torch.Size([1, 1179]) with length 1179 > the model's max sequence length of 1024.\n",
            "We shall truncate it ourselves. It's imperative if you correct this issue first.\n",
            " 97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 9673/10000 [44:00<01:26,  3.79it/s]Unsloth: Input IDs of shape torch.Size([1, 1125]) with length 1125 > the model's max sequence length of 1024.\n",
            "We shall truncate it ourselves. It's imperative if you correct this issue first.\n",
            " 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 9765/10000 [44:29<01:02,  3.78it/s]Unsloth: Input IDs of shape torch.Size([1, 1068]) with length 1068 > the model's max sequence length of 1024.\n",
            "We shall truncate it ourselves. It's imperative if you correct this issue first.\n",
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10000/10000 [45:35<00:00,  3.66it/s]\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_fa0ede21-ac69-4d4a-84b2-08557cf2c7d8\", \"submission.csv\", 105046)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Submission file 'submission.csv' created successfully!\n",
            "You can now download this file and submit it to the Kaggle competition.\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "from tqdm import tqdm\n",
        "from google.colab import files\n",
        "# Load the official test set\n",
        "\n",
        "test_dataset = load_dataset(\"ad6398/nyu-dl-teach-maths-comp\", split=\"test\")\n",
        "predictions = []\n",
        "\n",
        "# A simple function to parse 'True' or 'False' from the model's raw output\n",
        "def parse_output(response_text):\n",
        "    # Find the text after \"Output:\"\n",
        "    output_part = response_text.split(\"Output:\\n\")[-1]\n",
        "    # Check if \"True\" is in that part, case-insensitively\n",
        "    if 'true' in output_part.lower():\n",
        "        return True\n",
        "    return False\n",
        "\n",
        "# Loop through the test dataset and generate a prediction for each example\n",
        "for example in tqdm(test_dataset):\n",
        "    question = example[\"question\"]\n",
        "    solution = example[\"solution\"]\n",
        "\n",
        "    # Format the prompt\n",
        "    prompt = inference_prompt.format(question, str(solution))\n",
        "    inputs = tokenizer([prompt], return_tensors=\"pt\").to(\"cuda\")\n",
        "\n",
        "    # Generate the prediction\n",
        "    outputs = model.generate(**inputs, max_new_tokens=64,temperature=0,do_sample=False,use_cache=True)\n",
        "    response_text = tokenizer.batch_decode(outputs, skip_special_tokens=True)[0]\n",
        "\n",
        "    # Parse the prediction and add it to our list\n",
        "    prediction = parse_output(response_text)\n",
        "    predictions.append(prediction)\n",
        "\n",
        "# Create the submission DataFrame\n",
        "submission = pd.DataFrame({\n",
        "    'ID': range(len(predictions)),\n",
        "    'is_correct': predictions\n",
        "})\n",
        "\n",
        "# Save the DataFrame to a CSV file\n",
        "submission.to_csv('submission.csv', index=False)\n",
        "submission_path = \"/content/submission.csv\"\n",
        "files.download(submission_path)\n",
        "print(\"\\nSubmission file 'submission.csv' created successfully!\")\n",
        "print(\"You can now download this file and submit it to the Kaggle competition.\")"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "A100",
      "machine_shape": "hm",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
  },
  "nbformat": 4,
  "nbformat_minor": 0
}